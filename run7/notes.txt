[W907 22:03:17.853775866 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -> Tensor
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: AutocastCPU
  previous kernel: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:327
       new kernel: registered at /opt/workspace/ipex-cpu-dev/csrc/cpu/autocast/autocast_mode.cpp:112 (function operator())
2025-09-07 22:03:19,329 - _logger.py - torchao.kernel.intmm - WARNING - Warning: Detected no triton, on systems without Triton certain kernels will not work
Benchmark speed of model on CPU with 8 cores...
Benchmark speed of model: Qwen/Qwen3-30B-A3B-Instruct-2507
Input file: run7/task.json
Number of CPU cores to use: 8
Maximum number of output tokens: 150
Additional special settings: float32
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:01<00:15,  1.01s/it]Loading checkpoint shards:  12%|█▎        | 2/16 [00:02<00:15,  1.10s/it]Loading checkpoint shards:  19%|█▉        | 3/16 [00:03<00:14,  1.14s/it]Loading checkpoint shards:  25%|██▌       | 4/16 [00:04<00:13,  1.16s/it]Loading checkpoint shards:  31%|███▏      | 5/16 [00:05<00:12,  1.18s/it]Loading checkpoint shards:  38%|███▊      | 6/16 [00:06<00:11,  1.19s/it]Loading checkpoint shards:  44%|████▍     | 7/16 [00:08<00:10,  1.21s/it]Loading checkpoint shards:  50%|█████     | 8/16 [00:09<00:09,  1.22s/it]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:10<00:08,  1.23s/it]Loading checkpoint shards:  62%|██████▎   | 10/16 [00:11<00:07,  1.24s/it]Loading checkpoint shards:  69%|██████▉   | 11/16 [00:13<00:06,  1.26s/it]Loading checkpoint shards:  75%|███████▌  | 12/16 [00:14<00:05,  1.27s/it]Loading checkpoint shards:  81%|████████▏ | 13/16 [00:15<00:03,  1.27s/it]Loading checkpoint shards:  88%|████████▊ | 14/16 [00:17<00:02,  1.29s/it]Loading checkpoint shards:  94%|█████████▍| 15/16 [00:18<00:01,  1.30s/it]Loading checkpoint shards: 100%|██████████| 16/16 [00:18<00:00,  1.04it/s]Loading checkpoint shards: 100%|██████████| 16/16 [00:18<00:00,  1.17s/it]
Model dtype: torch.float32
Operation load_model took 20.99 seconds.
Operation load_input took 0.0 seconds.
Operation encode_input took 0.02 seconds.
Start iteration: 0
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_0 took 118.71 seconds.
Start iteration: 1
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_1 took 104.05 seconds.
Start iteration: 2
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_2 took 104.28 seconds.
Start iteration: 3
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_3 took 100.79 seconds.
Start iteration: 4
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_4 took 100.5 seconds.
Start iteration: 5
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_5 took 104.13 seconds.
Start iteration: 6
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_6 took 100.12 seconds.
Start iteration: 7
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_7 took 99.56 seconds.
Start iteration: 8
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_8 took 99.71 seconds.
Start iteration: 9
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_9 took 103.82 seconds.
Operation generate_llm took 1035.67 seconds.
Operation decode_outputs took 0.0 seconds.
Save to output file: run7/out-1-8.json
Done saving to output file.
[W907 22:21:01.265241998 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -> Tensor
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: AutocastCPU
  previous kernel: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:327
       new kernel: registered at /opt/workspace/ipex-cpu-dev/csrc/cpu/autocast/autocast_mode.cpp:112 (function operator())
2025-09-07 22:21:03,736 - _logger.py - torchao.kernel.intmm - WARNING - Warning: Detected no triton, on systems without Triton certain kernels will not work
Benchmark speed of model on CPU with 16 cores...
Benchmark speed of model: Qwen/Qwen3-30B-A3B-Instruct-2507
Input file: run7/task.json
Number of CPU cores to use: 16
Maximum number of output tokens: 150
Additional special settings: float32
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:00<00:10,  1.37it/s]Loading checkpoint shards:  12%|█▎        | 2/16 [00:01<00:11,  1.22it/s]Loading checkpoint shards:  19%|█▉        | 3/16 [00:02<00:11,  1.17it/s]Loading checkpoint shards:  25%|██▌       | 4/16 [00:03<00:10,  1.14it/s]Loading checkpoint shards:  31%|███▏      | 5/16 [00:04<00:09,  1.11it/s]Loading checkpoint shards:  38%|███▊      | 6/16 [00:05<00:09,  1.09it/s]Loading checkpoint shards:  44%|████▍     | 7/16 [00:06<00:08,  1.08it/s]Loading checkpoint shards:  50%|█████     | 8/16 [00:07<00:07,  1.06it/s]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:08<00:06,  1.05it/s]Loading checkpoint shards:  62%|██████▎   | 10/16 [00:09<00:05,  1.03it/s]Loading checkpoint shards:  69%|██████▉   | 11/16 [00:10<00:04,  1.02it/s]Loading checkpoint shards:  75%|███████▌  | 12/16 [00:11<00:03,  1.00it/s]Loading checkpoint shards:  81%|████████▏ | 13/16 [00:12<00:03,  1.01s/it]Loading checkpoint shards:  88%|████████▊ | 14/16 [00:13<00:02,  1.02s/it]Loading checkpoint shards:  94%|█████████▍| 15/16 [00:14<00:01,  1.04s/it]Loading checkpoint shards: 100%|██████████| 16/16 [00:14<00:00,  1.31it/s]Loading checkpoint shards: 100%|██████████| 16/16 [00:14<00:00,  1.10it/s]
Model dtype: torch.float32
Operation load_model took 16.93 seconds.
Operation load_input took 0.0 seconds.
Operation encode_input took 0.02 seconds.
Start iteration: 0
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_0 took 93.01 seconds.
Start iteration: 1
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_1 took 72.45 seconds.
Start iteration: 2
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_2 took 72.54 seconds.
Start iteration: 3
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_3 took 70.09 seconds.
Start iteration: 4
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_4 took 69.49 seconds.
Start iteration: 5
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_5 took 72.01 seconds.
Start iteration: 6
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_6 took 69.0 seconds.
Start iteration: 7
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_7 took 68.2 seconds.
Start iteration: 8
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_8 took 68.35 seconds.
Start iteration: 9
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_9 took 71.4 seconds.
Operation generate_llm took 726.55 seconds.
Operation decode_outputs took 0.0 seconds.
Save to output file: run7/out-1-16.json
Done saving to output file.
[W907 22:33:32.358227943 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -> Tensor
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: AutocastCPU
  previous kernel: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:327
       new kernel: registered at /opt/workspace/ipex-cpu-dev/csrc/cpu/autocast/autocast_mode.cpp:112 (function operator())
2025-09-07 22:33:34,882 - _logger.py - torchao.kernel.intmm - WARNING - Warning: Detected no triton, on systems without Triton certain kernels will not work
Benchmark speed of model on CPU with 32 cores...
Benchmark speed of model: Qwen/Qwen3-30B-A3B-Instruct-2507
Input file: run7/task.json
Number of CPU cores to use: 32
Maximum number of output tokens: 150
Additional special settings: float32
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:00<00:11,  1.31it/s]Loading checkpoint shards:  12%|█▎        | 2/16 [00:01<00:12,  1.17it/s]Loading checkpoint shards:  19%|█▉        | 3/16 [00:02<00:11,  1.12it/s]Loading checkpoint shards:  25%|██▌       | 4/16 [00:03<00:11,  1.09it/s]Loading checkpoint shards:  31%|███▏      | 5/16 [00:04<00:10,  1.07it/s]Loading checkpoint shards:  38%|███▊      | 6/16 [00:05<00:09,  1.04it/s]Loading checkpoint shards:  44%|████▍     | 7/16 [00:06<00:08,  1.03it/s]Loading checkpoint shards:  50%|█████     | 8/16 [00:07<00:07,  1.01it/s]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:08<00:07,  1.01s/it]Loading checkpoint shards:  62%|██████▎   | 10/16 [00:09<00:06,  1.03s/it]Loading checkpoint shards:  69%|██████▉   | 11/16 [00:10<00:05,  1.05s/it]Loading checkpoint shards:  75%|███████▌  | 12/16 [00:11<00:04,  1.06s/it]Loading checkpoint shards:  81%|████████▏ | 13/16 [00:13<00:03,  1.08s/it]Loading checkpoint shards:  88%|████████▊ | 14/16 [00:14<00:02,  1.09s/it]Loading checkpoint shards:  94%|█████████▍| 15/16 [00:15<00:01,  1.11s/it]Loading checkpoint shards: 100%|██████████| 16/16 [00:15<00:00,  1.22it/s]Loading checkpoint shards: 100%|██████████| 16/16 [00:15<00:00,  1.04it/s]
Model dtype: torch.float32
Operation load_model took 17.78 seconds.
Operation load_input took 0.0 seconds.
Operation encode_input took 0.03 seconds.
Start iteration: 0
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_0 took 107.49 seconds.
Start iteration: 1
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_1 took 82.88 seconds.
Start iteration: 2
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_2 took 83.61 seconds.
Start iteration: 3
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_3 took 79.47 seconds.
Start iteration: 4
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_4 took 78.98 seconds.
Start iteration: 5
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_5 took 82.21 seconds.
Start iteration: 6
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_6 took 78.66 seconds.
Start iteration: 7
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_7 took 78.06 seconds.
Start iteration: 8
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_8 took 77.98 seconds.
Start iteration: 9
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_9 took 81.66 seconds.
Operation generate_llm took 831.0 seconds.
Operation decode_outputs took 0.0 seconds.
Save to output file: run7/out-1-32.json
Done saving to output file.
[W907 22:47:49.117845503 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -> Tensor
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: AutocastCPU
  previous kernel: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:327
       new kernel: registered at /opt/workspace/ipex-cpu-dev/csrc/cpu/autocast/autocast_mode.cpp:112 (function operator())
2025-09-07 22:47:51,611 - _logger.py - torchao.kernel.intmm - WARNING - Warning: Detected no triton, on systems without Triton certain kernels will not work
Benchmark speed of model on CPU with 8 cores...
Benchmark speed of model: Qwen/Qwen3-30B-A3B-Instruct-2507
Input file: run7/task.json
Number of CPU cores to use: 8
Maximum number of output tokens: 150
Additional special settings: none
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:00<00:04,  3.33it/s]Loading checkpoint shards:  12%|█▎        | 2/16 [00:00<00:05,  2.68it/s]Loading checkpoint shards:  19%|█▉        | 3/16 [00:01<00:05,  2.48it/s]Loading checkpoint shards:  25%|██▌       | 4/16 [00:01<00:05,  2.35it/s]Loading checkpoint shards:  31%|███▏      | 5/16 [00:02<00:04,  2.24it/s]Loading checkpoint shards:  38%|███▊      | 6/16 [00:02<00:04,  2.16it/s]Loading checkpoint shards:  44%|████▍     | 7/16 [00:03<00:04,  2.09it/s]Loading checkpoint shards:  50%|█████     | 8/16 [00:03<00:03,  2.03it/s]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:04<00:03,  1.98it/s]Loading checkpoint shards:  62%|██████▎   | 10/16 [00:04<00:03,  1.92it/s]Loading checkpoint shards:  69%|██████▉   | 11/16 [00:05<00:02,  1.87it/s]Loading checkpoint shards:  75%|███████▌  | 12/16 [00:05<00:02,  1.83it/s]Loading checkpoint shards:  81%|████████▏ | 13/16 [00:06<00:01,  1.79it/s]Loading checkpoint shards:  88%|████████▊ | 14/16 [00:07<00:01,  1.75it/s]Loading checkpoint shards:  94%|█████████▍| 15/16 [00:07<00:00,  1.71it/s]Loading checkpoint shards: 100%|██████████| 16/16 [00:07<00:00,  2.08it/s]
Model dtype: torch.bfloat16
Operation load_model took 9.98 seconds.
Operation load_input took 0.0 seconds.
Operation encode_input took 0.02 seconds.
Start iteration: 0
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_0 took 75.55 seconds.
Start iteration: 1
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_1 took 76.17 seconds.
Start iteration: 2
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_2 took 76.2 seconds.
Start iteration: 3
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_3 took 75.69 seconds.
Start iteration: 4
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_4 took 73.69 seconds.
Start iteration: 5
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_5 took 75.27 seconds.
Start iteration: 6
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_6 took 73.51 seconds.
Start iteration: 7
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_7 took 72.62 seconds.
Start iteration: 8
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_8 took 77.25 seconds.
Start iteration: 9
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_9 took 79.25 seconds.
Operation generate_llm took 755.2 seconds.
Operation decode_outputs took 0.0 seconds.
Save to output file: run7/out-2-8.json
Done saving to output file.
[W907 23:00:39.096462817 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -> Tensor
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: AutocastCPU
  previous kernel: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:327
       new kernel: registered at /opt/workspace/ipex-cpu-dev/csrc/cpu/autocast/autocast_mode.cpp:112 (function operator())
2025-09-07 23:00:41,596 - _logger.py - torchao.kernel.intmm - WARNING - Warning: Detected no triton, on systems without Triton certain kernels will not work
Benchmark speed of model on CPU with 16 cores...
Benchmark speed of model: Qwen/Qwen3-30B-A3B-Instruct-2507
Input file: run7/task.json
Number of CPU cores to use: 16
Maximum number of output tokens: 150
Additional special settings: none
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:00<00:04,  3.23it/s]Loading checkpoint shards:  12%|█▎        | 2/16 [00:00<00:05,  2.51it/s]Loading checkpoint shards:  19%|█▉        | 3/16 [00:01<00:05,  2.29it/s]Loading checkpoint shards:  25%|██▌       | 4/16 [00:01<00:05,  2.13it/s]Loading checkpoint shards:  31%|███▏      | 5/16 [00:02<00:05,  2.02it/s]Loading checkpoint shards:  38%|███▊      | 6/16 [00:02<00:05,  1.95it/s]Loading checkpoint shards:  44%|████▍     | 7/16 [00:03<00:04,  1.88it/s]Loading checkpoint shards:  50%|█████     | 8/16 [00:04<00:04,  1.84it/s]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:04<00:03,  1.76it/s]Loading checkpoint shards:  62%|██████▎   | 10/16 [00:05<00:03,  1.71it/s]Loading checkpoint shards:  69%|██████▉   | 11/16 [00:05<00:02,  1.68it/s]Loading checkpoint shards:  75%|███████▌  | 12/16 [00:06<00:02,  1.65it/s]Loading checkpoint shards:  81%|████████▏ | 13/16 [00:07<00:01,  1.62it/s]Loading checkpoint shards:  88%|████████▊ | 14/16 [00:07<00:01,  1.60it/s]Loading checkpoint shards:  94%|█████████▍| 15/16 [00:08<00:00,  1.56it/s]Loading checkpoint shards: 100%|██████████| 16/16 [00:08<00:00,  1.88it/s]
Model dtype: torch.bfloat16
Operation load_model took 10.91 seconds.
Operation load_input took 0.0 seconds.
Operation encode_input took 0.02 seconds.
Start iteration: 0
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_0 took 58.17 seconds.
Start iteration: 1
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_1 took 60.96 seconds.
Start iteration: 2
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_2 took 61.3 seconds.
Start iteration: 3
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_3 took 60.36 seconds.
Start iteration: 4
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_4 took 58.74 seconds.
Start iteration: 5
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_5 took 62.54 seconds.
Start iteration: 6
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_6 took 59.21 seconds.
Start iteration: 7
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_7 took 57.6 seconds.
Start iteration: 8
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_8 took 57.79 seconds.
Start iteration: 9
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_9 took 61.44 seconds.
Operation generate_llm took 598.12 seconds.
Operation decode_outputs took 0.0 seconds.
Save to output file: run7/out-2-16.json
Done saving to output file.
[W907 23:10:53.973993370 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -> Tensor
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: AutocastCPU
  previous kernel: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:327
       new kernel: registered at /opt/workspace/ipex-cpu-dev/csrc/cpu/autocast/autocast_mode.cpp:112 (function operator())
2025-09-07 23:10:55,478 - _logger.py - torchao.kernel.intmm - WARNING - Warning: Detected no triton, on systems without Triton certain kernels will not work
Benchmark speed of model on CPU with 32 cores...
Benchmark speed of model: Qwen/Qwen3-30B-A3B-Instruct-2507
Input file: run7/task.json
Number of CPU cores to use: 32
Maximum number of output tokens: 150
Additional special settings: none
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:00<00:04,  3.10it/s]Loading checkpoint shards:  12%|█▎        | 2/16 [00:00<00:05,  2.40it/s]Loading checkpoint shards:  19%|█▉        | 3/16 [00:01<00:05,  2.18it/s]Loading checkpoint shards:  25%|██▌       | 4/16 [00:01<00:05,  2.04it/s]Loading checkpoint shards:  31%|███▏      | 5/16 [00:02<00:05,  1.94it/s]Loading checkpoint shards:  38%|███▊      | 6/16 [00:02<00:05,  1.86it/s]Loading checkpoint shards:  44%|████▍     | 7/16 [00:03<00:05,  1.80it/s]Loading checkpoint shards:  50%|█████     | 8/16 [00:04<00:04,  1.73it/s]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:04<00:04,  1.68it/s]Loading checkpoint shards:  62%|██████▎   | 10/16 [00:05<00:03,  1.64it/s]Loading checkpoint shards:  69%|██████▉   | 11/16 [00:06<00:03,  1.62it/s]Loading checkpoint shards:  75%|███████▌  | 12/16 [00:06<00:02,  1.58it/s]Loading checkpoint shards:  81%|████████▏ | 13/16 [00:07<00:01,  1.56it/s]Loading checkpoint shards:  88%|████████▊ | 14/16 [00:08<00:01,  1.56it/s]Loading checkpoint shards:  94%|█████████▍| 15/16 [00:08<00:00,  1.51it/s]Loading checkpoint shards: 100%|██████████| 16/16 [00:08<00:00,  1.81it/s]
Model dtype: torch.bfloat16
Operation load_model took 11.22 seconds.
Operation load_input took 0.0 seconds.
Operation encode_input took 0.03 seconds.
Start iteration: 0
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_0 took 77.81 seconds.
Start iteration: 1
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_1 took 76.93 seconds.
Start iteration: 2
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_2 took 79.15 seconds.
Start iteration: 3
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_3 took 76.51 seconds.
Start iteration: 4
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_4 took 78.02 seconds.
Start iteration: 5
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_5 took 81.09 seconds.
Start iteration: 6
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_6 took 81.45 seconds.
Start iteration: 7
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_7 took 78.61 seconds.
Start iteration: 8
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_8 took 78.47 seconds.
Start iteration: 9
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_9 took 85.26 seconds.
Operation generate_llm took 793.31 seconds.
Operation decode_outputs took 0.0 seconds.
Save to output file: run7/out-2-32.json
Done saving to output file.
[W907 23:24:22.367908397 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -> Tensor
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: AutocastCPU
  previous kernel: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:327
       new kernel: registered at /opt/workspace/ipex-cpu-dev/csrc/cpu/autocast/autocast_mode.cpp:112 (function operator())
2025-09-07 23:24:24,869 - _logger.py - torchao.kernel.intmm - WARNING - Warning: Detected no triton, on systems without Triton certain kernels will not work
Benchmark speed of model on CPU with 64 cores...
Benchmark speed of model: Qwen/Qwen3-30B-A3B-Instruct-2507
Input file: run7/task.json
Number of CPU cores to use: 64
Maximum number of output tokens: 150
Additional special settings: none
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:00<00:04,  3.08it/s]Loading checkpoint shards:  12%|█▎        | 2/16 [00:00<00:05,  2.40it/s]Loading checkpoint shards:  19%|█▉        | 3/16 [00:01<00:05,  2.20it/s]Loading checkpoint shards:  25%|██▌       | 4/16 [00:01<00:05,  2.08it/s]Loading checkpoint shards:  31%|███▏      | 5/16 [00:02<00:05,  1.99it/s]Loading checkpoint shards:  38%|███▊      | 6/16 [00:02<00:05,  1.92it/s]Loading checkpoint shards:  44%|████▍     | 7/16 [00:03<00:04,  1.82it/s]Loading checkpoint shards:  50%|█████     | 8/16 [00:04<00:04,  1.78it/s]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:04<00:04,  1.71it/s]Loading checkpoint shards:  62%|██████▎   | 10/16 [00:05<00:03,  1.66it/s]Loading checkpoint shards:  69%|██████▉   | 11/16 [00:06<00:03,  1.64it/s]Loading checkpoint shards:  75%|███████▌  | 12/16 [00:06<00:02,  1.62it/s]Loading checkpoint shards:  81%|████████▏ | 13/16 [00:07<00:01,  1.61it/s]Loading checkpoint shards:  88%|████████▊ | 14/16 [00:07<00:01,  1.59it/s]Loading checkpoint shards:  94%|█████████▍| 15/16 [00:08<00:00,  1.56it/s]Loading checkpoint shards: 100%|██████████| 16/16 [00:08<00:00,  1.85it/s]
Model dtype: torch.bfloat16
Operation load_model took 11.05 seconds.
Operation load_input took 0.0 seconds.
Operation encode_input took 0.02 seconds.
Start iteration: 0
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_0 took 478.63 seconds.
Start iteration: 1
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_1 took 494.22 seconds.
Start iteration: 2
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_2 took 487.17 seconds.
Start iteration: 3
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_3 took 482.34 seconds.
Start iteration: 4
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_4 took 474.82 seconds.
Start iteration: 5
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_5 took 505.14 seconds.
Start iteration: 6
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_6 took 497.15 seconds.
Start iteration: 7
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_7 took 460.35 seconds.
Start iteration: 8
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_8 took 455.26 seconds.
Start iteration: 9
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_9 took 496.41 seconds.
Operation generate_llm took 4831.5 seconds.
Operation decode_outputs took 0.0 seconds.
Save to output file: run7/out-2-64.json
Done saving to output file.
[W908 00:45:10.771928290 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -> Tensor
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: AutocastCPU
  previous kernel: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:327
       new kernel: registered at /opt/workspace/ipex-cpu-dev/csrc/cpu/autocast/autocast_mode.cpp:112 (function operator())
2025-09-08 00:45:12,260 - _logger.py - torchao.kernel.intmm - WARNING - Warning: Detected no triton, on systems without Triton certain kernels will not work
Benchmark speed of model on CPU with 8 cores...
Benchmark speed of model: Qwen/Qwen3-30B-A3B-Instruct-2507
Input file: run7/task.json
Number of CPU cores to use: 8
Maximum number of output tokens: 150
Additional special settings: intel_optimize
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:00<00:04,  3.11it/s]Loading checkpoint shards:  12%|█▎        | 2/16 [00:00<00:05,  2.42it/s]Loading checkpoint shards:  19%|█▉        | 3/16 [00:01<00:05,  2.19it/s]Loading checkpoint shards:  25%|██▌       | 4/16 [00:01<00:05,  2.05it/s]Loading checkpoint shards:  31%|███▏      | 5/16 [00:02<00:05,  1.98it/s]Loading checkpoint shards:  38%|███▊      | 6/16 [00:02<00:05,  1.89it/s]Loading checkpoint shards:  44%|████▍     | 7/16 [00:03<00:04,  1.82it/s]Loading checkpoint shards:  50%|█████     | 8/16 [00:04<00:04,  1.79it/s]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:04<00:04,  1.72it/s]Loading checkpoint shards:  62%|██████▎   | 10/16 [00:05<00:03,  1.66it/s]Loading checkpoint shards:  69%|██████▉   | 11/16 [00:06<00:03,  1.61it/s]Loading checkpoint shards:  75%|███████▌  | 12/16 [00:06<00:02,  1.59it/s]Loading checkpoint shards:  81%|████████▏ | 13/16 [00:07<00:01,  1.57it/s]Loading checkpoint shards:  88%|████████▊ | 14/16 [00:08<00:01,  1.56it/s]Loading checkpoint shards:  94%|█████████▍| 15/16 [00:08<00:00,  1.51it/s]Loading checkpoint shards: 100%|██████████| 16/16 [00:08<00:00,  1.82it/s]
Model dtype: torch.bfloat16
Operation load_model took 20.66 seconds.
Operation load_input took 0.0 seconds.
Operation encode_input took 0.03 seconds.
Start iteration: 0
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_0 took 70.1 seconds.
Start iteration: 1
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_1 took 70.5 seconds.
Start iteration: 2
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_2 took 72.32 seconds.
Start iteration: 3
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_3 took 70.16 seconds.
Start iteration: 4
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_4 took 69.01 seconds.
Start iteration: 5
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_5 took 71.85 seconds.
Start iteration: 6
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_6 took 71.16 seconds.
Start iteration: 7
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_7 took 71.22 seconds.
Start iteration: 8
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_8 took 70.26 seconds.
Start iteration: 9
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_9 took 72.46 seconds.
Operation generate_llm took 709.05 seconds.
Operation decode_outputs took 0.0 seconds.
Save to output file: run7/out-3-8.json
Done saving to output file.
[W908 00:57:27.619529552 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -> Tensor
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: AutocastCPU
  previous kernel: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:327
       new kernel: registered at /opt/workspace/ipex-cpu-dev/csrc/cpu/autocast/autocast_mode.cpp:112 (function operator())
2025-09-08 00:57:29,085 - _logger.py - torchao.kernel.intmm - WARNING - Warning: Detected no triton, on systems without Triton certain kernels will not work
Benchmark speed of model on CPU with 16 cores...
Benchmark speed of model: Qwen/Qwen3-30B-A3B-Instruct-2507
Input file: run7/task.json
Number of CPU cores to use: 16
Maximum number of output tokens: 150
Additional special settings: intel_optimize
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:00<00:04,  3.15it/s]Loading checkpoint shards:  12%|█▎        | 2/16 [00:00<00:05,  2.45it/s]Loading checkpoint shards:  19%|█▉        | 3/16 [00:01<00:05,  2.26it/s]Loading checkpoint shards:  25%|██▌       | 4/16 [00:01<00:05,  2.14it/s]Loading checkpoint shards:  31%|███▏      | 5/16 [00:02<00:05,  2.04it/s]Loading checkpoint shards:  38%|███▊      | 6/16 [00:02<00:05,  1.97it/s]Loading checkpoint shards:  44%|████▍     | 7/16 [00:03<00:04,  1.91it/s]Loading checkpoint shards:  50%|█████     | 8/16 [00:03<00:04,  1.86it/s]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:04<00:03,  1.81it/s]Loading checkpoint shards:  62%|██████▎   | 10/16 [00:05<00:03,  1.77it/s]Loading checkpoint shards:  69%|██████▉   | 11/16 [00:05<00:02,  1.73it/s]Loading checkpoint shards:  75%|███████▌  | 12/16 [00:06<00:02,  1.70it/s]Loading checkpoint shards:  81%|████████▏ | 13/16 [00:06<00:01,  1.67it/s]Loading checkpoint shards:  88%|████████▊ | 14/16 [00:07<00:01,  1.64it/s]Loading checkpoint shards:  94%|█████████▍| 15/16 [00:08<00:00,  1.57it/s]Loading checkpoint shards: 100%|██████████| 16/16 [00:08<00:00,  1.91it/s]
Model dtype: torch.bfloat16
Operation load_model took 18.89 seconds.
Operation load_input took 0.0 seconds.
Operation encode_input took 0.02 seconds.
Start iteration: 0
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_0 took 56.64 seconds.
Start iteration: 1
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_1 took 56.6 seconds.
Start iteration: 2
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_2 took 57.64 seconds.
Start iteration: 3
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_3 took 56.15 seconds.
Start iteration: 4
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_4 took 55.04 seconds.
Start iteration: 5
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_5 took 57.21 seconds.
Start iteration: 6
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_6 took 56.51 seconds.
Start iteration: 7
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_7 took 56.77 seconds.
Start iteration: 8
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_8 took 55.83 seconds.
Start iteration: 9
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_9 took 57.28 seconds.
Operation generate_llm took 565.68 seconds.
Operation decode_outputs took 0.0 seconds.
Save to output file: run7/out-3-16.json
Done saving to output file.
[W908 01:07:19.417049547 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -> Tensor
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: AutocastCPU
  previous kernel: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:327
       new kernel: registered at /opt/workspace/ipex-cpu-dev/csrc/cpu/autocast/autocast_mode.cpp:112 (function operator())
2025-09-08 01:07:20,904 - _logger.py - torchao.kernel.intmm - WARNING - Warning: Detected no triton, on systems without Triton certain kernels will not work
Benchmark speed of model on CPU with 32 cores...
Benchmark speed of model: Qwen/Qwen3-30B-A3B-Instruct-2507
Input file: run7/task.json
Number of CPU cores to use: 32
Maximum number of output tokens: 150
Additional special settings: intel_optimize
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:00<00:04,  3.10it/s]Loading checkpoint shards:  12%|█▎        | 2/16 [00:00<00:05,  2.44it/s]Loading checkpoint shards:  19%|█▉        | 3/16 [00:01<00:05,  2.24it/s]Loading checkpoint shards:  25%|██▌       | 4/16 [00:01<00:05,  2.11it/s]Loading checkpoint shards:  31%|███▏      | 5/16 [00:02<00:05,  2.01it/s]Loading checkpoint shards:  38%|███▊      | 6/16 [00:02<00:05,  1.92it/s]Loading checkpoint shards:  44%|████▍     | 7/16 [00:03<00:04,  1.83it/s]Loading checkpoint shards:  50%|█████     | 8/16 [00:04<00:04,  1.80it/s]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:04<00:04,  1.74it/s]Loading checkpoint shards:  62%|██████▎   | 10/16 [00:05<00:03,  1.69it/s]Loading checkpoint shards:  69%|██████▉   | 11/16 [00:05<00:03,  1.66it/s]Loading checkpoint shards:  75%|███████▌  | 12/16 [00:06<00:02,  1.62it/s]Loading checkpoint shards:  81%|████████▏ | 13/16 [00:07<00:01,  1.59it/s]Loading checkpoint shards:  88%|████████▊ | 14/16 [00:07<00:01,  1.57it/s]Loading checkpoint shards:  94%|█████████▍| 15/16 [00:08<00:00,  1.54it/s]Loading checkpoint shards: 100%|██████████| 16/16 [00:08<00:00,  1.85it/s]
Model dtype: torch.bfloat16
Operation load_model took 20.55 seconds.
Operation load_input took 0.0 seconds.
Operation encode_input took 0.02 seconds.
Start iteration: 0
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_0 took 70.54 seconds.
Start iteration: 1
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_1 took 71.5 seconds.
Start iteration: 2
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_2 took 72.76 seconds.
Start iteration: 3
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_3 took 70.49 seconds.
Start iteration: 4
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_4 took 68.79 seconds.
Start iteration: 5
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_5 took 71.71 seconds.
Start iteration: 6
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_6 took 70.89 seconds.
Start iteration: 7
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_7 took 71.07 seconds.
Start iteration: 8
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_8 took 70.09 seconds.
Start iteration: 9
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_9 took 72.51 seconds.
Operation generate_llm took 710.35 seconds.
Operation decode_outputs took 0.0 seconds.
Save to output file: run7/out-3-32.json
Done saving to output file.
[W908 01:19:37.641203997 OperatorEntry.cpp:218] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -> Tensor
    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6
  dispatch key: AutocastCPU
  previous kernel: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:327
       new kernel: registered at /opt/workspace/ipex-cpu-dev/csrc/cpu/autocast/autocast_mode.cpp:112 (function operator())
2025-09-08 01:19:39,111 - _logger.py - torchao.kernel.intmm - WARNING - Warning: Detected no triton, on systems without Triton certain kernels will not work
Benchmark speed of model on CPU with 64 cores...
Benchmark speed of model: Qwen/Qwen3-30B-A3B-Instruct-2507
Input file: run7/task.json
Number of CPU cores to use: 64
Maximum number of output tokens: 150
Additional special settings: intel_optimize
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|▋         | 1/16 [00:00<00:04,  3.33it/s]Loading checkpoint shards:  12%|█▎        | 2/16 [00:00<00:05,  2.66it/s]Loading checkpoint shards:  19%|█▉        | 3/16 [00:01<00:05,  2.45it/s]Loading checkpoint shards:  25%|██▌       | 4/16 [00:01<00:05,  2.31it/s]Loading checkpoint shards:  31%|███▏      | 5/16 [00:02<00:05,  2.19it/s]Loading checkpoint shards:  38%|███▊      | 6/16 [00:02<00:04,  2.09it/s]Loading checkpoint shards:  44%|████▍     | 7/16 [00:03<00:04,  2.01it/s]Loading checkpoint shards:  50%|█████     | 8/16 [00:03<00:04,  1.94it/s]Loading checkpoint shards:  56%|█████▋    | 9/16 [00:04<00:03,  1.86it/s]Loading checkpoint shards:  62%|██████▎   | 10/16 [00:04<00:03,  1.80it/s]Loading checkpoint shards:  69%|██████▉   | 11/16 [00:05<00:02,  1.75it/s]Loading checkpoint shards:  75%|███████▌  | 12/16 [00:06<00:02,  1.69it/s]Loading checkpoint shards:  81%|████████▏ | 13/16 [00:06<00:01,  1.66it/s]Loading checkpoint shards:  88%|████████▊ | 14/16 [00:07<00:01,  1.63it/s]Loading checkpoint shards:  94%|█████████▍| 15/16 [00:08<00:00,  1.57it/s]Loading checkpoint shards: 100%|██████████| 16/16 [00:08<00:00,  1.96it/s]
Model dtype: torch.bfloat16
Operation load_model took 22.36 seconds.
Operation load_input took 0.0 seconds.
Operation encode_input took 0.02 seconds.
Start iteration: 0
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_0 took 372.71 seconds.
Start iteration: 1
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Operation generate_iter_1 took 393.79 seconds.
Start iteration: 2
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
